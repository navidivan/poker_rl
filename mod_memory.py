# -*- coding: utf-8 -*-
"""Untitled48.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QvmyUtRjVoxuDhjUxKG_XAesHiDeTtKR
"""

# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZGAYzn2SZYNP8Uazy_TMvP0wD_GLkeV

#MC Tree formations

##Visualization
"""

import numpy as np
import pandas as pd
import copy

from mod_poker_5 import *
from mod_fe import *
from mod_agents import *
import torch as T



from mod_poker_decide import *

class MCT_decide(object):
  def __init__(self, input_shape = 62, debug =False, num_rounds=4, starting_ronds= [1,2,3,4], num_samples=10000 ):
    self.input_shape = input_shape
    self.debug = debug
    self.size = num_samples

    self.starting_ronds = starting_ronds
    self.num_rounds = num_rounds
    self.b_index=0
    self.num_samples = num_samples
    self.size= self.num_samples
###
  def Make_Memory(self):

    self.obs_now = np.zeros((self.size, self.input_shape))
    self.rewards = -99 * np.ones((self.size, 1))
    print('making memory', self.num_samples)

    poker = Poker_decide(num_rounds = self.num_rounds, starting_ronds=self.starting_ronds, debug=False)

    for i in range(self.num_samples):
      poker = Poker_decide(num_rounds = self.num_rounds, starting_ronds=self.starting_ronds, debug=False)
      obs_get = fe_dummy(poker.obs)
      self.obs_now[i,:] = obs_get
      self.rewards[i,0] = poker.decide()
###

  def cont_buffer(self, batch_size=16):
    try:
      batch = np.arange(self.b_index, self.b_index + batch_size)
      self.b_index += batch_size
      states = self.obs_now[batch]
      rewards = self.rewards[batch]
    except:
      self.b_index= 0
      batch = np.arange(self.b_index, self.b_index + batch_size)
      self.b_index += batch_size
      states = self.obs_now[batch]
      rewards = self.rewards[batch]
    if -99 in rewards:
        print('fucked up! found a -99 entry')
    return states, rewards

################################################
import copy
def MCT_rollout(poker, a, b, option_size =7, parent =''):
  poker.single_hand = True
  AV = np.empty(7)
  AV[:] = np.NaN
  if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
    options = poker.obs['player0_options'].copy()
    obs_get = poker.player_obs(poker.obs['agent_id']).copy()
    feat = feature_engineering(obs_get)
    act_selected = a.action(options, feat)
    a.epsilon=0
    b.epsilon=0
    dummy_opts = act_selected
    for opt in range(len(dummy_opts)):
      if dummy_opts[opt] == 0:
        continue
      else:
        inter_poker = copy.deepcopy(poker)
        intial_stack = inter_poker.obs['stacks'][0]
        obs, rews, last_action = inter_poker.step(act_selected)
        while inter_poker.game_ended == 0:
          if inter_poker.obs['agent_id'] == 0 and inter_poker.hand_ended == 0:
            obs_get = inter_poker.player_obs(inter_poker.obs['agent_id']).copy()
            act_get =  a.action(inter_poker.obs['player0_options'], feature_engineering(obs_get))
            obs, rews, last_action = inter_poker.step(act_get)
    
          elif inter_poker.obs['agent_id'] == 1 and inter_poker.hand_ended == 0:
            obs_get = inter_poker.player_obs(inter_poker.obs['agent_id']).copy()
            act_get =  b.action(inter_poker.obs['player1_options'], feature_engineering_p1(obs_get))
            obs, rews, last_action = inter_poker.step(act_get)
          else:
            obs, rews, last_action = inter_poker.step(None)
    
          if inter_poker.hand_ended == 1:
            rews=inter_poker.rewards
        end_stack = inter_poker.obs['stacks'][0]
        AV[opt] = end_stack - intial_stack

    return feat, AV, np.array(act_selected), np.array(options)


#@#############################################
class MCT_Memory(object):
  def __init__(self, num_samples=40,  input_shape = 62, debug =False, num_rounds=4):
    self.input_shape = input_shape
    self.num_samples = num_samples
    self.debug = debug
    self.size = copy.deepcopy(num_samples)

    self.obs_now = -99 * np.ones((self.size, self.input_shape))
    self.rewards = np.ones((self.size, 7))
    self.actions = -99 * np.ones((self.size, 7))
    self.options = -99 * np.ones((self.size, 7))
    self.action_number = -1
    self.index=0
    self.sample=0
    self.num_rounds = num_rounds
    self.target = self.size
    self.num_games = 0
    self.num_games_p0d = 0
    self.b_index = 0
    self.consider = 100
    self.init_stack = 100.0

  def Reset_Memory(self, new_shape = 20000):
    self.b_index=0
    self.size = new_shape
    if self.debug: print('reseting memory to ', self.size)
    self.obs_now = -99 * np.ones((self.size, self.input_shape))
    self.rewards = np.ones((self.size, 7))
    self.actions =-99 * np.ones((self.size, 7))
    self.options =-99 * np.ones((self.size, 7))
    self.action_number = -1
    self.index=0
    self.rews = [0 , 0]
    self.sample=0
    self.num_games = 0
    self.num_games_p0d = 0
    
  def Double_Memory(self):
    self.b_index=0
    self.index = self.size
    self.size = self.size * 2
    if self.debug: print('doubling memory to ', self.size)
    self.obs_now = np.vstack([self.obs_now , self.obs_now ])
    self.rewards = np.vstack([self.rewards , self.rewards ])
    self.actions = np.vstack([self.actions , self.actions ])
    self.options = np.vstack([self.options , self.options ])
    self.rews = [0 , 0]

###
  def Make_Memory(self,  a, b, default = False):
    self.b_index = 0
    self.sample = 0
    self.target = min(self.index + self.num_samples, self.size)
    print('starting from', self.index, 'setting target to', self.target)
    while self.sample < self.num_samples and self.index<self.size:
      poker = Poker_5(single_hand=True)
      self.num_games += 1
      if poker.initial_dealer == 0:
        self.num_games_p0d += 1

      while poker.hand_ended == 0:
          while poker.obs['agent_id'] != 0 and poker.hand_ended == 0:
            if poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
              obs_get_p1 = poker.player_obs(poker.obs['agent_id']).copy()
              act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get_p1))
              obs, rews, last_action = poker.step(act_get)
            else:
              obs, rews, last_action = poker.step(None)
          if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
            if self.debug : print(poker.obs['dealer'])
            
            if default == False:
                a.epsilon = 0
            obs_matrix, AV_matrix, act_matrix, opt_matrix= MCT_rollout(poker, a=a, b=b)
            self.sample += obs_matrix.shape[0]
            if self.debug:
              print('{} new samples generated'.format(obs_matrix.shape[0]))
              # print('total samples are now', self.sample, 'out of', self.num_samples)
    
            # if self.sample > min(self.num_samples,self.size-self.index):
            if obs_matrix.shape[0] > self.size-self.index:
              try:
                obs_matrix = obs_matrix [:self.target-self.index,:]
                AV_matrix = AV_matrix [:self.target-self.index,:]
                act_matrix = act_matrix [:self.target-self.index,:]
                opt_matrix = opt_matrix [:self.target-self.index,:]        
                if self.debug : print('AV_matrix', AV_matrix)
              except:
                obs_matrix= obs_matrix.reshape(1,-1)
                AV_matrix= AV_matrix.reshape(1,-1)
                act_matrix= act_matrix.reshape(1,-1)     
                opt_matrix= opt_matrix.reshape(1,-1)                 
                if self.debug: 
                  print ('failed something*************************************!')
                  print('self.target', self.target)
                  print('self.index', self.index)
                  print('AV_matrix', AV_matrix)
                  print('AV_matrix shape', AV_matrix.shape)
                print('1st exception, obs_matrix reshaped to', obs_matrix)
    
    
              if self.debug: 
                print('Triming obs_matrix to ', obs_matrix.shape[0])
            try:
              self.obs_now[self.index : self.index+obs_matrix.shape[0] , :] = obs_matrix
              self.rewards[self.index : self.index+obs_matrix.shape[0] , :] = AV_matrix
              self.actions[self.index : self.index+obs_matrix.shape[0] , :] = act_matrix
              self.options[self.index : self.index+obs_matrix.shape[0] , :] = opt_matrix              
              if self.debug: print('updating memory from {} to {}'.format(self.index, self.index+obs_matrix.shape[0]))
              if self.debug: print('intital dealer/ game number/ num_games_p0d', poker.initial_dealer, self.num_games, self.num_games_p0d)
            except: 
              print ('second exception and error, target was', self.obs_now[self.index : self.index+obs_matrix.shape[0] , :])
              print ('target shape was', self.obs_now[self.index : self.index+obs_matrix.shape[0] , :].shape)
              print ('obs_matrix was', obs_matrix)
              print('obs_matrix shape was,', obs_matrix.shape)
              print ('AV_matrix was', AV_matrix)
              print('self.index = ', self.index)
              print('self.size = ', self.size)
              print('obs_now shape was', self.obs_now[self.index : self.index+obs_matrix.shape[0] , :].shape)

            #doing the exploratory action
            if default == False:
                a.epsilon = 1
            obs_get_p0 = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get_p0))
            obs, rews, last_action = poker.step(act_get)
            self.index += obs_matrix.shape[0]
      if self.debug: print('index to', self.index)
      a.epsilon = 0
    if self.index == self.size:
      self.index=0
    if self.debug: print('reeeesetting index to', self.index)
###
  def add_memory(self, count, a, b):
    if count > self.obs_now.shape[0]:
        print('cant create more than you have!')
        return 0
    self.b_index=0
    self.index = self.size
    self.size = self.size + count
    print('adding', count, 'memory to ', self.size)
    self.obs_now = np.vstack([self.obs_now , self.obs_now[:count] ])
    self.rewards = np.vstack([self.rewards , self.rewards[:count] ])
    self.actions = np.vstack([self.actions , self.actions[:count] ])
    self.options = np.vstack([self.options , self.options[:count] ])
    self.rews = [0 , 0]
    self.num_samples = count
    self.Make_Memory(a, b)   

  def shuffle_memory(self):
    print ('shuffling...')
    perm = np.arange(self.rewards.shape[0])
    np.random.shuffle(perm)
    self.rewards = self.rewards[perm]
    self.obs_now = self.obs_now[perm]
    self.actions = self.actions[perm]
    self.options = self.options[perm]

  def cont_buffer(self, batch_size=16, t = 1):
    total = self.init_stack
    try:
      batch = np.arange(self.b_index, self.b_index + batch_size)
      self.b_index += batch_size
      states = self.obs_now[batch]
      rewards = self.rewards[batch]
      actions = self.actions[batch]
      options = self.options[batch]
    except:
      self.b_index= 0
      self.shuffle_memory()
      batch = np.arange(self.b_index, self.b_index + batch_size)
      self.b_index += batch_size
      states = self.obs_now[batch]
      rewards = self.rewards[batch]
      actions = self.actions[batch]
      options = self.options[batch]
    mask = ~np.ma.masked_invalid(rewards).mask
    rewards[~mask]=0
    rewards = rewards/total
    if -99 in states:
        print('fucked up! found a -99 entry')
    return states, rewards, options, actions