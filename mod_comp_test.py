# -*- coding: utf-8 -*-
"""Untitled49.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yzdaM-t5sXo8yESVxjaN5DnYaUhyONxF
"""

import numpy as np
import pandas as pd
import copy
from mod_poker_5 import *
from mod_fe import *
from mod_agents import *

def bench(a , b=Agent_Simple_Rational(), debug=False):
  winners = []
  for i in range(100):
    # print(i)
    poker = Poker_5(debug=debug,single_hand=False)
    log = ""
    while poker.game_ended == 0:

        
      # print('put = ', poker.obs['put'])
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:

        # action_number+=1
        # index = action_number % num_samples
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # obs_now[index,:] = feature_engineering(obs_get)
        act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
        # actions[index] = np.nonzero(act_get)[0]

        # if obs_next[index-1,0] != 1 :
          # obs_next[index-1,:] = feature_engineering(obs_get)
          # actions_next[index-1] = np.nonzero(act_get)[0]
        obs, rews, last_action = poker.step(act_get)
        # rewards[index] = last_action[0]

      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # print(feature_engineering(obs_get))
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)

      if poker.hand_ended == 1:
        rews=poker.rewards
        # print('sample to update: ', action_number)
        # index = action_number % num_samples
        # rewards[index] += rews[0]
        # obs_next[index,0] = 1 
        row_added=1
    # print(poker.game_winner)
    winners.append(poker.game_winner)
  win_per_Azero = 1 - np.count_nonzero(winners)/len(winners)
  return win_per_Azero

def bench_AV(a , b=Agent_Simple_Rational(), debug=False):
  winners = []
  for i in range(100):
    # print(i)
    poker = Poker_5(debug=debug,single_hand=False)
    log = ""
    while poker.game_ended == 0:

        
      # print('put = ', poker.obs['put'])
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:

        # action_number+=1
        # index = action_number % num_samples
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # obs_now[index,:] = feature_engineering(obs_get)
        act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
        # actions[index] = np.nonzero(act_get)[0]

        # if obs_next[index-1,0] != 1 :
          # obs_next[index-1,:] = feature_engineering(obs_get)
          # actions_next[index-1] = np.nonzero(act_get)[0]
        obs, rews, last_action = poker.step(act_get)
        # rewards[index] = last_action[0]

      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # print(feature_engineering(obs_get))
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)

      if poker.hand_ended == 1:
        rews=poker.rewards
        # print('sample to update: ', action_number)
        # index = action_number % num_samples
        # rewards[index] += rews[0]
        # obs_next[index,0] = 1 
        row_added=1
    # print(poker.game_winner)
    winners.append(poker.game_winner)
  win_per_Azero = 1 - np.count_nonzero(winners)/len(winners)
  return win_per_Azero

def bench_hands(a , b=Agent_Simple_Rational()):
  winners = []
  for i in range(1000):
    # print(i)
    poker = Poker_5(single_hand=True)
    log = ""
    intial_stack = poker.obs['stacks'][0]
    while poker.game_ended == 0:
      # print('put = ', poker.obs['put'])
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:

        # action_number+=1
        # index = action_number % num_samples
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # obs_now[index,:] = feature_engineering(obs_get)
        act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
        # actions[index] = np.nonzero(act_get)[0]

        # if obs_next[index-1,0] != 1 :
          # obs_next[index-1,:] = feature_engineering(obs_get)
          # actions_next[index-1] = np.nonzero(act_get)[0]
        obs, rews, last_action = poker.step(act_get)
        # rewards[index] = last_action[0]

      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # print(feature_engineering(obs_get))
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)

      if poker.hand_ended == 1:
        rews=poker.rewards
        # print('sample to update: ', action_number)
        # index = action_number % num_samples
        # rewards[index] += rews[0]
        # obs_next[index,0] = 1 
        row_added=1
    end_stack = poker.obs['stacks'][0]
    winners.append(end_stack -intial_stack )
  win_per_Azero = np.mean(np.array(winners))
  return win_per_Azero
  
def bench_hands_AV(a , b=Agent_Simple_Rational()):
  winners = []
  for i in range(1000):
    # print(i)
    poker = Poker_5(single_hand=True)
    log = ""
    intial_stack = poker.obs['stacks'][0]
    while poker.game_ended == 0:
      # print('put = ', poker.obs['put'])
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:

        # action_number+=1
        # index = action_number % num_samples
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # obs_now[index,:] = feature_engineering(obs_get)
        act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
        # actions[index] = np.nonzero(act_get)[0]

        # if obs_next[index-1,0] != 1 :
          # obs_next[index-1,:] = feature_engineering(obs_get)
          # actions_next[index-1] = np.nonzero(act_get)[0]
        obs, rews, last_action = poker.step(act_get)
        # rewards[index] = last_action[0]

      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        # print(feature_engineering(obs_get))
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)

      if poker.hand_ended == 1:
        rews=poker.rewards
        # print('sample to update: ', action_number)
        # index = action_number % num_samples
        # rewards[index] += rews[0]
        # obs_next[index,0] = 1 
        row_added=1
    end_stack = poker.obs['stacks'][0]
    winners.append(end_stack -intial_stack )
  win_per_Azero = np.mean(np.array(winners))
  return win_per_Azero

def comp_test(agent_a):
  winners = []
  a= agent_a
  b= Agent_Call_Any()
  c= Agent_Raise_Any()
  d= Agent_Random()
  e= Agent_Simple_Rational()
  f= Agent_Simple_Equity()
  g= Agent_Allin_Any()

  agent_a.epsilon = 0
  print(agent_a.temp, 'atemp')

  Agents=[a,b,c,d,e,f,g]
  Agents_Array = 0.5*np.ones((len(Agents), len(Agents)))

  columns, index = [],[]
  for agent in Agents:
    columns.append(agent.name)
    index.append(agent.name)

  import time

  winners = []
  for x,a in enumerate(Agents):
    for y,b in enumerate(Agents):
      if a==b:
        continue
      winners = []
      for i in range(100):
        poker = Poker_5()
        log = ""
        while poker.game_ended == 0:
          row_added=0
          if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
            obs, rews, last_action = poker.step(act_get)
          elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
            obs, rews, last_action = poker.step(act_get)
          else:
            obs, rews, last_action = poker.step(None)
          if poker.hand_ended == 1:
            rews=poker.rewards
            row_added=1
        winners.append(poker.game_winner)
      win_per_Azero = np.count_nonzero(winners)/len(winners)
      print('{a} won {p} from {b}'.format(a=Agents[x].name, p=(1-win_per_Azero)*100, b=Agents[y].name))
      Agents_Array[x,y] = 1- np.count_nonzero(winners)/len(winners)

  log = pd.DataFrame(data=Agents_Array, index=index, columns=columns)
  return log
###############################
def comp_test_AV(agent_a):
  winners = []
  a= agent_a
  b= Agent_Call_Any()
  c= Agent_Raise_Any()
  d= Agent_Random()
  e= Agent_Simple_Rational()
  f= Agent_Simple_Equity()
  g= Agent_Allin_Any()

  agent_a.epsilon = 0
  print(agent_a.temp, 'atemp')

  Agents=[a,b,c,d,e,f,g]
  Agents_Array = 0.5*np.ones((len(Agents), len(Agents)))

  columns, index = [],[]
  for agent in Agents:
    columns.append(agent.name)
    index.append(agent.name)

  import time

  winners = []
  for x,a in enumerate(Agents):
    for y,b in enumerate(Agents):
      if a==b:
        continue
      winners = []
      for i in range(100):
        poker = Poker_5()
        log = ""
        while poker.game_ended == 0:
          row_added=0
          if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
            obs, rews, last_action = poker.step(act_get)
          elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
            obs, rews, last_action = poker.step(act_get)
          else:
            obs, rews, last_action = poker.step(None)
          if poker.hand_ended == 1:
            rews=poker.rewards
            row_added=1
        winners.append(poker.game_winner)
      win_per_Azero = np.count_nonzero(winners)/len(winners)
      print('{a} won {p} from {b}'.format(a=Agents[x].name, p=(1-win_per_Azero)*100, b=Agents[y].name))
      Agents_Array[x,y] = 1- np.count_nonzero(winners)/len(winners)

  log = pd.DataFrame(data=Agents_Array, index=index, columns=columns)
  return log
####
def tornument(Agents):

  Agents_Array = 0.5*np.ones((len(Agents), len(Agents)))

  for agent in Agents:
    agent.epsilon = 0

  columns, index = [],[]
  for agent in Agents:
    columns.append(agent.name)
    index.append(agent.name)

  import time

  winners = []
  for x,a in enumerate(Agents):
    for y,b in enumerate(Agents):
      try:
        if abs(int(a.name) - int(b.name)) == 1 :
          continue
      except:
        pass
      winners = []
      for i in range(40):
        poker = Poker_5()
        log = ""
        steps = 0
        while poker.game_ended == 0:
          steps+=1
          if steps>1000:
            poker.game_winner = np.argmax(poker.obs['stacks'])
            print('breaking!')
            break
          row_added=0
          if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
            obs, rews, last_action = poker.step(act_get)
          elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
            obs_get = poker.player_obs(poker.obs['agent_id']).copy()
            act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
            obs, rews, last_action = poker.step(act_get)
          else:
            obs, rews, last_action = poker.step(None)
          if poker.hand_ended == 1:
            rews=poker.rewards
            row_added=1
        winners.append(poker.game_winner)
      win_per_Azero = np.count_nonzero(winners)/len(winners)
      print('{a} won {p} from {b}'.format(a=Agents[x].name, p=(1-win_per_Azero)*100, b=Agents[y].name))
      Agents_Array[x,y] = 1- np.count_nonzero(winners)/len(winners)

  log = pd.DataFrame(data=Agents_Array, index=index, columns=columns)

  return log
###############################  
def compare(a, recents):

  winners = []
  Agents=[a] + recents
  Agents_Array = 0.5*np.ones((1, len(Agents)))

  for agent in Agents:
    agent.epsilon = 0
    agent.temp= 0.01

  columns, index = [],[a.name]
  for agent in Agents:
    columns.append(agent.name)

  for y,b in enumerate(Agents):
    if a==b:
      continue
    winners = []
    for i in range(20):
      poker = Poker_5()
      log = ""
      steps = 0
      while poker.game_ended == 0:
        steps+=1
        if steps>1000:
          poker.game_winner = np.argmax(poker.obs['stacks'])
          print('breaking!')
          break
        row_added=0
        if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
          obs, rews, last_action = poker.step(act_get)
        elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
          obs, rews, last_action = poker.step(act_get)
        else:
          obs, rews, last_action = poker.step(None)
        if poker.hand_ended == 1:
          rews=poker.rewards
          row_added=1
      winners.append(poker.game_winner)
    win_per_Azero = np.count_nonzero(winners)/len(winners)
    print('{a} won {p} from {b}'.format(a=Agents[0].name, p=(1-win_per_Azero)*100, b=Agents[y].name))
    Agents_Array[0,y] = 1- np.count_nonzero(winners)/len(winners)

  log = pd.DataFrame(data=Agents_Array, index=index, columns=columns)
  return log
##########
def analyze(a , b=Agent_Simple_Rational()):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  winners = []
  base = np.zeros((1,7))
  for i in range(1000):
    poker = Poker_5(single_hand=True)
    log = ""
    intial_stack = poker.obs['stacks'][0]
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
        base[0, np.nonzero(act_get)] += 1
        obs, rews, last_action = poker.step(act_get)
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards
        row_added=1
    end_stack = poker.obs['stacks'][0]
    winners.append(end_stack -intial_stack )
  win_per_Azero = np.mean(np.array(winners))
  base = base/np.sum(base) * 100
  return win_per_Azero , base

def analyze_probs(a , b=Agent_Simple_Rational(), pokers = None):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  acts_1 = np.zeros((1,7))

  if pokers is None:
    pokers = []
    print("making pokers")
    for i in range(1000):
      poker = Poker_5(single_hand=True)
      while poker.game_ended == 0:
        row_added=0
        if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
          acts_1 = np.vstack([acts_1, act_get])
          pokers.append(copy.deepcopy(poker))
          break
        elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
          obs, rews, last_action = poker.step(act_get)
        else:
          obs, rews, last_action = poker.step(None)
        if poker.hand_ended == 1:
          rews=poker.rewards
          row_added=1
    return acts_1, pokers
  else:
    for p in pokers:
      poker = copy.deepcopy(p)
      while poker.game_ended == 0:
        row_added=0
        if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
          acts_1 = np.vstack([acts_1, act_get])
          break
        elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
          obs, rews, last_action = poker.step(act_get)
        else:
          obs, rews, last_action = poker.step(None)
        if poker.hand_ended == 1:
          rews=poker.rewards
          row_added=1
    return acts_1, pokers 
    
def analyze_probs_fast(a , b=Agent_Simple_Rational()):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  acts_1 = np.zeros((1,7))

  pokers = []
  print("making pokers")
  for i in range(1000):
    poker = Poker_5(single_hand=True)
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
        acts_1 = np.vstack([acts_1, act_get])
        pokers.append(copy.deepcopy(poker))
        break
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards

  acts_2 = np.zeros((1,7))
  for p in pokers:
    poker = copy.deepcopy(p)
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action(poker.obs['player0_options'], feature_engineering(obs_get))
        acts_2 = np.vstack([acts_2, act_get])
        break
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards
        row_added=1
  return np.mean((acts_1 - acts_2)**2)
##################
def analyze_AV(a , b=Agent_Simple_Rational()):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  winners = []
  base = np.zeros((1,7))
  for i in range(1000):
    poker = Poker_5(single_hand=True)
    log = ""
    intial_stack = poker.obs['stacks'][0]
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
        base[0, np.nonzero(act_get)] += 1
        obs, rews, last_action = poker.step(act_get)
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards
        row_added=1
    end_stack = poker.obs['stacks'][0]
    winners.append(end_stack -intial_stack )
  win_per_Azero = np.mean(np.array(winners))
  base = base/np.sum(base) * 100
  return win_per_Azero , base

def analyze_probs_AV(a , b=Agent_Simple_Rational(), pokers = None):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  acts_1 = np.zeros((1,7))

  if pokers is None:
    pokers = []
    print("making pokers")
    for i in range(1000):
      poker = Poker_5(single_hand=True)
      while poker.game_ended == 0:
        row_added=0
        if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
          acts_1 = np.vstack([acts_1, act_get])
          pokers.append(copy.deepcopy(poker))
          break
        elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
          obs, rews, last_action = poker.step(act_get)
        else:
          obs, rews, last_action = poker.step(None)
        if poker.hand_ended == 1:
          rews=poker.rewards
          row_added=1
    return acts_1, pokers
  else:
    for p in pokers:
      poker = copy.deepcopy(p)
      while poker.game_ended == 0:
        row_added=0
        if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
          acts_1 = np.vstack([acts_1, act_get])
          break
        elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
          obs_get = poker.player_obs(poker.obs['agent_id']).copy()
          act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
          obs, rews, last_action = poker.step(act_get)
        else:
          obs, rews, last_action = poker.step(None)
        if poker.hand_ended == 1:
          rews=poker.rewards
          row_added=1
    return acts_1, pokers 
    
def analyze_probs_fast_AV(a , b=Agent_Simple_Rational()):
  try:
    print(a.temp, 'atemp')
  except:
    pass
  try:
    print(b.temp, 'btemp')
  except:
    pass
  a.epsilon = 0
  b.epsilon = 0
  acts_1 = np.zeros((1,7))

  pokers = []
  print("making pokers")
  for i in range(1000):
    poker = Poker_5(single_hand=True)
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
        acts_1 = np.vstack([acts_1, act_get])
        pokers.append(copy.deepcopy(poker))
        break
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards

  acts_2 = np.zeros((1,7))
  for p in pokers:
    poker = copy.deepcopy(p)
    while poker.game_ended == 0:
      row_added=0
      if poker.obs['agent_id'] == 0 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  a.action_AV(poker.obs['player0_options'], feature_engineering(obs_get))
        acts_2 = np.vstack([acts_2, act_get])
        break
      elif poker.obs['agent_id'] == 1 and poker.hand_ended == 0:
        obs_get = poker.player_obs(poker.obs['agent_id']).copy()
        act_get =  b.action(poker.obs['player1_options'], feature_engineering_p1(obs_get))
        obs, rews, last_action = poker.step(act_get)
      else:
        obs, rews, last_action = poker.step(None)
      if poker.hand_ended == 1:
        rews=poker.rewards
        row_added=1
  return np.mean((acts_1 - acts_2)**2)